const experiences = [
  {
    companyName: "University of Illinois at Chicago, Chicago, Illinois",
    timePeriod: "Sept 2023 - Dec 2023",
    position: "Graduate Teaching Assistant",
    imageUrl: "image/uic.png",
    summary: [
      "Visualization and Visual Data Analytics: Organized office hours to help 30+ graduate students work on visualizations and graded assignments.",
      "Program Design I in the Context of Biological Problems: Conducted Lab sessions and office hours with with coursework in Python with topics: Data Types, Contional Statements, Loops and Plotting.",
    ],
  },
  {
    companyName: "Regions Bank, Birmingham, Alabama",
    timePeriod: "May 2023 - Aug 2023",
    position: "Software Engineering Intern, Lending Data Services ",
    imageUrl: "image/regions-bank.png",
    summary: [
      "Restful API: Migrated 10 RESTful API controllers from Monolith architecture to Micro-services Architecture using .NET 6 and C#9, resulting in enhanced API response.",
      "Database: Optimized the SQL storage procedures and performed integrations with relational and NoSQL databases.",
      "Optimization: Optimized the source code by implementing common functionality for all micro-services, improved code efficiency and maintenance index from around 60 to 80.",
    ],
  },

  {
    companyName: "Hewlett Packard Enterprise Bengaluru, India",
    timePeriod: "Jan 2020 - April 2022",
    imageUrl: "image/hpe.png",
    position:
      "System Software Engineer I, Research and Development - Tools for Servers",
    summary: [
      "Cloud: Developed and maintained over 20 configuration procedures for private cloud environments, ensuring high availability and efficient deployment of complex cloud architecture solutions.",
      "DevOps: Automated client-site private cloud product deployment and validation, including distributed clusters, virtualization, and container platforms, using Python, Java, and PowerShell.",
      "Firmware: Enhanced server component management via RESTful APIs with a Python automation library that decreased manual efforts by more than 50%, streamlining network, storage, and OS operations.",
      "Big Data: Built Python scripts to collect, augment, and ingest the data into Hadoop cluster of 7 nodes and processed data parallel using Spark (pyspark) which reduced the time by 300% and helped in benchmarking of the servers.",
      "Real-time Monitoring : Designed a data visualization platform using Prometheus (Time-Series Database) and Graphana (Data Visualization Software) for live monitoring of 30 parameters of 50 nodes in 4 different clusters.",
      "Debugging: Resolved and patched more than 50 software defects related to virtual machines, operating systems, networks, switches, protocols, storage and security reported by internal customers using C++, Python, PowerShell, and Java.",
      "Deployment: Automated the application deployment using Ansible and pipepline using Jenkins.",
    ],
  },
  // Add more experiences as needed
];

export default experiences;
